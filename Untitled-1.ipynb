{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aede52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import numpy as np\n",
    "from Classes.Analysis import Analysis\n",
    "from Classes.Visualizer import Visualizer\n",
    "import h5py\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from Classes.UltimateAnalysis import UltimateAnalysis\n",
    "import dask.dataframe as dd\n",
    "\n",
    "class System(Analysis):\n",
    "    def __init__(self, graph_location):\n",
    "        super().__init__(graph_location)\n",
    "\n",
    "    def odesystem(self, t, Y, *params):\n",
    "        # start simple, bacteria-resource, see how the bacteria and reosurces grow/shrink, bacteria should hit carrying capacity, resource should reach 0, not negative, etc\n",
    "        graph_object, phage_nodes, bacteria_nodes, resource_nodes, M, e_vector, tau_vector, v_matrix, K_matrix, r_matrix, B_matrix, environment = params\n",
    "        graph = graph_object.graph\n",
    "        def g(N, v, K):\n",
    "            return (N * v) / (N + K)\n",
    "\n",
    "        Y = self.check_cutoff(Y)\n",
    "        \n",
    "        N, U, I, P = self.unflatten_initial_matrix(Y, [len(resource_nodes), len(bacteria_nodes), (len(bacteria_nodes), M), len(phage_nodes)])\n",
    "        new_N = np.zeros_like(N)\n",
    "        new_U = np.zeros_like(U)\n",
    "        new_I = np.zeros_like(I)\n",
    "        new_P = np.zeros_like(P)\n",
    "        #update N vector\n",
    "        for resource in resource_nodes:\n",
    "            n_index = resource_nodes.index(resource)\n",
    "            e_value = e_vector[n_index] \n",
    "            sum_g = 0\n",
    "            sum_u = 0\n",
    "            sum_i = 0\n",
    "            for bacteria in bacteria_nodes:\n",
    "                b_index = bacteria_nodes.index(bacteria)\n",
    "                if graph.has_edge(bacteria, resource):\n",
    "                    v = v_matrix[b_index, n_index]\n",
    "                    K = K_matrix[b_index, n_index]\n",
    "                    sum_g += g(N[n_index], v, K)\n",
    "                    sum_u += U[b_index]\n",
    "                    sum_i += np.sum(I[b_index])\n",
    "            new_N[n_index] = -(e_value * sum_g) * (sum_u + sum_i) - N[n_index] * environment['washout']\n",
    "        \n",
    "        # update U vector, i, and j are flipped relative to what is seen in update N vector for v, K, and r matrices because of how the row and columns are defined in the graph\n",
    "        # dont sum U in left and right, because we are looking at an individual bacteria\n",
    "        for uninfected in bacteria_nodes:\n",
    "            u_index = bacteria_nodes.index(uninfected)\n",
    "            g_sum = 0\n",
    "            right = 0\n",
    "            for resource in resource_nodes:\n",
    "                n_index = resource_nodes.index(resource)\n",
    "                if graph.has_edge(uninfected, resource):\n",
    "                    g_sum += g(N[n_index], v_matrix[u_index, n_index], K_matrix[u_index, n_index])\n",
    "            for phage in phage_nodes:\n",
    "                p_index = phage_nodes.index(phage)\n",
    "                if graph.has_edge(phage, uninfected):\n",
    "                    right += r_matrix[p_index, u_index] * P[p_index]\n",
    "            new_U[u_index] = g_sum * U[u_index] - right * U[u_index] - U[u_index] * environment['washout']\n",
    "\n",
    "        for infected in bacteria_nodes:\n",
    "            i_index = bacteria_nodes.index(infected)\n",
    "            for infected_stage in range(0, M):\n",
    "                if infected_stage == 0:\n",
    "                    left_sum = 0\n",
    "                    right_sum = 0\n",
    "                    for phage in phage_nodes:\n",
    "                        p_index = phage_nodes.index(phage)\n",
    "                        if graph.has_edge(phage, infected):\n",
    "                            left_sum += r_matrix[p_index, i_index] * P[p_index]\n",
    "                            right_sum += M / tau_vector[i_index] * I[i_index, 0]\n",
    "                    new_I[i_index, 0] = left_sum * U[i_index] - right_sum - U[i_index] * environment['washout']\n",
    "                else:\n",
    "                    m_tau = M / tau_vector[i_index]\n",
    "                    right = I[i_index, infected_stage - 1] - I[i_index, infected_stage]\n",
    "                    new_I[i_index, infected_stage] = m_tau * right - new_I[i_index, infected_stage] * environment['washout']\n",
    "        \n",
    "        for phage in phage_nodes:\n",
    "            p_index = phage_nodes.index(phage)\n",
    "            left_sum = 0\n",
    "            right_sum = 0\n",
    "            for infected in bacteria_nodes:\n",
    "                i_index = bacteria_nodes.index(infected)\n",
    "                if graph.has_edge(phage, infected):\n",
    "                    left_sum += B_matrix[p_index, i_index] * M / tau_vector[i_index] * I[i_index, -1]\n",
    "                    right_sum += r_matrix[p_index, i_index] * (U[i_index] + np.sum(I[i_index])) * P[p_index]\n",
    "            new_P[p_index] = left_sum - right_sum - P[p_index] * environment['washout']\n",
    "\n",
    "        flattened_y1 = self.flatten_lists_and_matrices(new_N, new_U, new_I, new_P)\n",
    "        return flattened_y1\n",
    "\n",
    "\n",
    "# graph = GraphMakerGUI()\n",
    "# graph.export_graph('simple_test.gexf')\n",
    "# graph = System('simple_test.gexf')\n",
    "\n",
    "# graph = System('example.gexf')\n",
    "# system = System('simple_test_2.gexf')\n",
    "system = System('example_3.gexf')\n",
    "# system.add_item_to_class_attribute('M', 4) # add the M value to the system\n",
    "\n",
    "phage_nodes = system.get_nodes_of_type('P')\n",
    "bacteria_nodes = system.get_nodes_of_type('B')\n",
    "resource_nodes = system.get_nodes_of_type('R')\n",
    "environemnt_nodes = system.get_nodes_of_type('E')\n",
    "\n",
    "R0 = system.initialize_new_parameter_from_node(resource_nodes, \"Initial_Concentration\")\n",
    "U0 = system.initialize_new_parameter_from_node(bacteria_nodes, \"Initial_Population\")\n",
    "I0 = system.initialize_new_matrix(len(U0), system.M)\n",
    "P0 = system.initialize_new_parameter_from_node(phage_nodes, \"Initial_Population\")\n",
    "\n",
    "e_vector = system.initialize_new_parameter_from_node(resource_nodes, 'e')\n",
    "tau_vector = system.initialize_new_parameter_from_node(bacteria_nodes, 'tau')\n",
    "v_matrix = system.initialize_new_parameter_from_edges(bacteria_nodes, resource_nodes, 'v')\n",
    "K_matrix = system.initialize_new_parameter_from_edges(bacteria_nodes, resource_nodes, 'K')\n",
    "r_matrix = system.initialize_new_parameter_from_edges(phage_nodes, bacteria_nodes, 'r')\n",
    "B_matrix = system.initialize_new_parameter_from_edges(phage_nodes, bacteria_nodes, 'Burst_Size')\n",
    "\n",
    "visualizer = Visualizer(system)\n",
    "visualizer.add_graph_data(\"Resources\", R0, resource_nodes)\n",
    "visualizer.add_graph_data(\"Uninfected Bacteria\", U0, bacteria_nodes)\n",
    "visualizer.add_graph_data(\"Infected Bacteria\", I0, row_names=bacteria_nodes, column_names=[f\"Infected B{i}\" for i in range(int(system.M))], add_rows=4)\n",
    "visualizer.add_graph_data(\"Phages\", P0 , phage_nodes)\n",
    "\n",
    "visualizer.add_non_graph_data_vector(\"e_vector\", e_vector, resource_nodes)\n",
    "visualizer.add_non_graph_data_vector(\"tau_vector\", tau_vector, bacteria_nodes)\n",
    "visualizer.add_non_graph_data_matrix(\"v_matrix\", v_matrix, bacteria_nodes, resource_nodes)\n",
    "visualizer.add_non_graph_data_matrix(\"K_matrix\", K_matrix, bacteria_nodes, resource_nodes)\n",
    "visualizer.add_non_graph_data_matrix(\"r_matrix\", r_matrix, phage_nodes, bacteria_nodes)\n",
    "visualizer.add_non_graph_data_matrix(\"B_matrix\", B_matrix, phage_nodes, bacteria_nodes)\n",
    "\n",
    "visualizer.add_other_parameters(phage_nodes, bacteria_nodes, resource_nodes, int(system.M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080a2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.integrate import solve_ivp\n",
    "\n",
    "# t_eval = np.linspace(0, 20, 100)\n",
    "# paramater_names = ['a', 'b', 'c']\n",
    "# params_to_test = [[1, 2, 3], [4, 5, 6], [1, 8, 9], [7, 8, 9], [1, 5, 3]]\n",
    "\n",
    "# def function(t, a):\n",
    "#     a_val, b_val, c_val = a[0], a[1], a[2]\n",
    "#     # Simulate function returning a NumPy array (like time or y data)\n",
    "#     return np.array([0.1 * a_val + b_val, 2.3 * c_val, a_val * c_val])\n",
    "# values = Parallel(n_jobs=-1)(delayed(\n",
    "#     lambda x: solve_ivp(function, (0, 20), x)\n",
    "# )(x) for x in params_to_test)\n",
    "\n",
    "# output_filename = 'function_results_test.hdf5'\n",
    "# with h5py.File(output_filename, 'w') as hf:\n",
    "#     # Add metadata to the root of the file\n",
    "#     hf.attrs['parameter_names_used'] = paramater_names  # Store metadata as attributes\n",
    "#     hf.attrs['parameter_values_tested'] = params_to_test  # Store analysis object as an attribute\n",
    "\n",
    "#     # Create a group to store the results\n",
    "#     # Store the parameters as a dataset\n",
    "#     # results_group.create_dataset('parameter_values_tested', data=np.array(params_to_test))\n",
    "#     for i, item in enumerate(values):\n",
    "#         results_group = hf.create_group(f'results_{i+1}')\n",
    "#         results_group.create_dataset(f'y_values', data=item.y)\n",
    "#         results_group.create_dataset(f't_values', data=item.t)\n",
    "#         for param_name, param_value in zip(paramater_names, params_to_test[i]):\n",
    "#             results_group.attrs[param_name] = param_value  # Store parameter values as attributes\n",
    "# hf.close()\n",
    "\n",
    "# print(f\"Results and parameters saved to {output_filename}\")\n",
    "\n",
    "# dictionary = {\n",
    "#     'parameter_names_used': paramater_names,\n",
    "#     'parameter_values_tested': params_to_test,\n",
    "#     'analysis': visualizer.analysis,\n",
    "#     'graph_data': visualizer.graph_data,\n",
    "#     'non_graph_data_vector': visualizer.non_graph_data_vector,\n",
    "#     'non_graph_data_matrix': visualizer.non_graph_data_matrix,\n",
    "#     'settings': visualizer.settings,\n",
    "#     'environment_data': visualizer.analysis.environment_data,\n",
    "#     'other_parameters': visualizer.other_parameters_to_pass,\n",
    "#     'hdf_file_location': 'function_results_test.hdf5',\n",
    "# }\n",
    "\n",
    "# pickle.dump(dictionary, open('function_results_test.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77801778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ua = UltimateAnalysis()\n",
    "# ua.unpack_pickle('function_results_test.pickle')\n",
    "# query1 = ua.new_query()\n",
    "\n",
    "# with h5py.File(query1, 'r') as query_in_memory:\n",
    "#     print(\"original dataset\", list(query_in_memory.keys()))\n",
    "\n",
    "\n",
    "# d = ua.simple_query(query1, 'Infected Bacteria', '==', 7)\n",
    "# with h5py.File(d, 'r') as d_in_memory:\n",
    "#     print(\"simulations with infected==7\", list(d_in_memory.keys()))\n",
    "\n",
    "# e = ua.simple_query(query1, 'Infected Bacteria', '==', 8)\n",
    "# with h5py.File(e, 'r') as e_in_memory:\n",
    "#     print(\"simulations with infected==8\", list(e_in_memory.keys())) \n",
    "\n",
    "# f = ua.simple_query(e, 'Resources', '>=', 2)\n",
    "# with h5py.File(f, 'r') as f_in_memory:\n",
    "#     print(\"simulations with Resources >=2\", list(f_in_memory.keys())) \n",
    "\n",
    "# g = ua.and_query(query1, ['Infected Bacteria', 'Resources'], ['==', '=='], [9, 1])\n",
    "# with h5py.File(g, 'r') as g_in_memory:\n",
    "#     print(\"simulations with infected=9 and Resources==1\", list(g_in_memory.keys())) \n",
    "\n",
    "# h = ua.or_query(query1, ['Resources', 'Resources'], ['<', '>'], [2, 2])\n",
    "# with h5py.File(h, 'r') as h_in_memory:\n",
    "#     print(\"simulations with resources<2 or Resources>2\", list(h_in_memory.keys())) \n",
    "\n",
    "# dictionary = ua.finalize_query(h)\n",
    "# print(dictionary)\n",
    "# dataframe = ua.finalize_query(d, format='dataframe')\n",
    "# save dataframe to csv\n",
    "# dataframe[dataframe['Resources'] == 1]\n",
    "# print(dataframe.iloc[0]['t_values'])\n",
    "# for i in range(0, len(dataframe.iloc[0]['y_values'])):\n",
    "#     print(dataframe.iloc[0]['y_values'][i])\n",
    "# print(d)\n",
    "# d2 = ua.simple_query(d, 'Resources', '==', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e65acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from pprint import pprint\n",
    "\n",
    "# pickle_object = pd.read_pickle('simulation_results.pickle')\n",
    "# dataframe = pickle_object['simulation_results']\n",
    "# dfr10 = dataframe[dataframe['Resources'] == 1]\n",
    "# print(dfr10)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Values\")\n",
    "# sim1 = dataframe.iloc[0]\n",
    "# for i in range(len(sim1['y_values'])):\n",
    "#     plt.plot(sim1['t_values'], sim1['y_values'][i], label=f\"item {i}\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "508b2912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.007280111312866211 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau_vector</th>\n",
       "      <th>washout</th>\n",
       "      <th>t_values</th>\n",
       "      <th>y_values</th>\n",
       "      <th>Resources</th>\n",
       "      <th>e_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 5.123596586316593e-05, 0.000563595624494...</td>\n",
       "      <td>[[150.0, 149.99342563749028, 149.9276371732764...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[0.0, 5.130984480789072e-05, 0.000564408292886...</td>\n",
       "      <td>[[150.0, 149.99340846115987, 149.9274481636362...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.005</td>\n",
       "      <td>[0.0, 5.160736477647414e-05, 0.000567681012541...</td>\n",
       "      <td>[[150.0, 149.99333927553215, 149.9266868402044...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 5.123596586316593e-05, 0.000563595624494...</td>\n",
       "      <td>[[150.0, 149.99342563748652, 149.9276371715017...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[0.0, 5.130984480789072e-05, 0.000564408292886...</td>\n",
       "      <td>[[150.0, 149.9934084611561, 149.92744816185694...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tau_vector  washout                                           t_values  \\\n",
       "0         0.4      0.0  [0.0, 5.123596586316593e-05, 0.000563595624494...   \n",
       "1         0.4    0.001  [0.0, 5.130984480789072e-05, 0.000564408292886...   \n",
       "2         0.4    0.005  [0.0, 5.160736477647414e-05, 0.000567681012541...   \n",
       "3    0.488889      0.0  [0.0, 5.123596586316593e-05, 0.000563595624494...   \n",
       "4    0.488889    0.001  [0.0, 5.130984480789072e-05, 0.000564408292886...   \n",
       "\n",
       "                                            y_values Resources e_vector  \n",
       "0  [[150.0, 149.99342563749028, 149.9276371732764...     150.0      0.8  \n",
       "1  [[150.0, 149.99340846115987, 149.9274481636362...     150.0      0.8  \n",
       "2  [[150.0, 149.99333927553215, 149.9266868402044...     150.0      0.8  \n",
       "3  [[150.0, 149.99342563748652, 149.9276371715017...     150.0      0.8  \n",
       "4  [[150.0, 149.9934084611561, 149.92744816185694...     150.0      0.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.13190507888793945 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unordered Categoricals can only compare equality or not",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecution_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Query the data in parquet_data\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Filter rows where 'Resources' is equal to 150\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# filtered_data = ddf.query('tau_vector>= 0.7')\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# result = filtered_data.compute()\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# display(result)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m res = \u001b[43mddf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mResources >= 160\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# display(ddf.head())\u001b[39;00m\n\u001b[32m     45\u001b[39m time1 = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/dask/dataframe/dask_expr/_collection.py:3664\u001b[39m, in \u001b[36mDataFrame.query\u001b[39m\u001b[34m(self, expr, **kwargs)\u001b[39m\n\u001b[32m   3594\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, expr, **kwargs):\n\u001b[32m   3595\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Filter dataframe with complex expression\u001b[39;00m\n\u001b[32m   3596\u001b[39m \n\u001b[32m   3597\u001b[39m \u001b[33;03m    Blocked version of pd.DataFrame.query\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3662\u001b[39m \u001b[33;03m    2  1  3    2\u001b[39;00m\n\u001b[32m   3663\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/dask/_collections.py:8\u001b[39m, in \u001b[36mnew_collection\u001b[39m\u001b[34m(expr)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_collection\u001b[39m(expr):\n\u001b[32m      7\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create new collection from an expr\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     meta = \u001b[43mexpr\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_meta\u001b[49m\n\u001b[32m      9\u001b[39m     expr._name  \u001b[38;5;66;03m# Ensure backend is imported\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_collection_type(meta)(expr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/functools.py:1001\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m    999\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1003\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/dask/dataframe/dask_expr/_expr.py:561\u001b[39m, in \u001b[36mBlockwise._meta\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;129m@functools\u001b[39m.cached_property\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    560\u001b[39m     args = [op._meta \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, Expr) \u001b[38;5;28;01melse\u001b[39;00m op \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._args]\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/dask/utils.py:1226\u001b[39m, in \u001b[36mmethodcaller.__call__\u001b[39m\u001b[34m(self, _methodcaller__obj, *args, **kwargs)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, __obj, *args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m__obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4823\u001b[39m, in \u001b[36mDataFrame.query\u001b[39m\u001b[34m(self, expr, inplace, **kwargs)\u001b[39m\n\u001b[32m   4821\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m) + \u001b[32m1\u001b[39m\n\u001b[32m   4822\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4823\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4825\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4826\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.loc[res]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4949\u001b[39m, in \u001b[36mDataFrame.eval\u001b[39m\u001b[34m(self, expr, inplace, **kwargs)\u001b[39m\n\u001b[32m   4946\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m\n\u001b[32m   4947\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mresolvers\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mtuple\u001b[39m(kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mresolvers\u001b[39m\u001b[33m\"\u001b[39m, ())) + resolvers\n\u001b[32m-> \u001b[39m\u001b[32m4949\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/computation/eval.py:357\u001b[39m, in \u001b[36meval\u001b[39m\u001b[34m(expr, parser, engine, local_dict, global_dict, resolvers, level, target, inplace)\u001b[39m\n\u001b[32m    355\u001b[39m eng = ENGINES[engine]\n\u001b[32m    356\u001b[39m eng_inst = eng(parsed_expr)\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m ret = \u001b[43meng_inst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parsed_expr.assigner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m multi_line:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/computation/engines.py:134\u001b[39m, in \u001b[36mPythonEngine.evaluate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/computation/expr.py:812\u001b[39m, in \u001b[36mExpr.__call__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    811\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mterms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/computation/ops.py:385\u001b[39m, in \u001b[36mBinOp.__call__\u001b[39m\u001b[34m(self, env)\u001b[39m\n\u001b[32m    382\u001b[39m left = \u001b[38;5;28mself\u001b[39m.lhs(env)\n\u001b[32m    383\u001b[39m right = \u001b[38;5;28mself\u001b[39m.rhs(env)\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(left, right)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/arraylike.py:60\u001b[39m, in \u001b[36mOpsMixin.__ge__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__ge__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/series.py:6119\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6116\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6117\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6119\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:330\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mLengths must match to compare\u001b[39m\u001b[33m\"\u001b[39m, lvalues.shape, rvalues.shape\n\u001b[32m    323\u001b[39m         )\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    326\u001b[39m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[32m    327\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m lvalues.dtype != \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    328\u001b[39m ):\n\u001b[32m    329\u001b[39m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     res_values = op(lvalues, rvalues)\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator.ne:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/pandas/core/arrays/categorical.py:135\u001b[39m, in \u001b[36m_cat_compare_op.<locals>.func\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ordered:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m opname \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m__lt__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__gt__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__le__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__ge__\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    136\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mUnordered Categoricals can only compare equality or not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m         )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Categorical):\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# Two Categoricals can only be compared if the categories are\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# the same (maybe up to ordering, depending on ordered)\u001b[39;00m\n\u001b[32m    142\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mCategoricals can only be compared if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcategories\u001b[39m\u001b[33m'\u001b[39m\u001b[33m are the same.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Unordered Categoricals can only compare equality or not"
     ]
    }
   ],
   "source": [
    "# Load the Parquet file\n",
    "# df = pd.read_csv('simulation_results.parquet')\n",
    "import sys\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "parquet_file_path = 'SimulationResults/UltimateAnalysis/simulation_results_1746521334.parquet'\n",
    "time1 = time.time()\n",
    "ddf = dd.read_parquet(parquet_file_path, engine='pyarrow', \n",
    "                      include_partition_columns=True, \n",
    "                      gather_statistics=True, \n",
    "                    #   columns=['Resources', 'Uninfected Bacteria', 'e_vector', 't_values'], \n",
    "                    #   filters=[('Resources', '==', \"2.0\"), (\"Uninfected Bacteria\", \">=\", \"11.1\")], \n",
    "                      dtype_backend='pyarrow')\n",
    "ddf['Resources'] = ddf['Resources'].astype('float64')\n",
    "ddf['e_vector'] = ddf['e_vector'].astype('float64')\n",
    "time2 = time.time()\n",
    "execution_time = time2 - time1\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "display(ddf.compute().head())\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "# Query the data in parquet_data\n",
    "# Filter rows where 'Resources' is equal to 150\n",
    "# filtered_data = ddf.query('tau_vector>= 0.7')\n",
    "# result = filtered_data.compute()\n",
    "# display(result)\n",
    "res = ddf.query(\"Resources >= 160\")\n",
    "# display(ddf.head())\n",
    "time1 = time.time()\n",
    "display(res.compute().head())\n",
    "time2 = time.time()\n",
    "execution_time = time2 - time1\n",
    "print(f\"Execution time: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "412f173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "import dask\n",
    "client = Client(threads_per_worker=4, n_workers=1)\n",
    "client\n",
    "def import_and_filter_parquet():\n",
    "    parquet_file_path = 'SimulationResults/UltimateAnalysis/simulation_results_1746205712.parquet'\n",
    "    parquet_data = dd.read_parquet(parquet_file_path)\n",
    "    # Query the data in parquet_data\n",
    "    # Filter rows where 'Resources' is equal to 150\n",
    "    filtered_data = parquet_data.query('Resources == 150')\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52e38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_result = dask.delayed(import_and_filter_parquet)()\n",
    "filtered_data = dask.compute(lazy_result)\n",
    "# result = filtered_data.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2b558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time loading file: 0.03380131721496582 seconds\n",
      "Execution time computing whole tbale: 1.811981201171875e-05 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resources</th>\n",
       "      <th>Uninfected Bacteria</th>\n",
       "      <th>e_vector</th>\n",
       "      <th>tau_vector</th>\n",
       "      <th>K_matrix</th>\n",
       "      <th>B_matrix</th>\n",
       "      <th>washout</th>\n",
       "      <th>t_values</th>\n",
       "      <th>y_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 7.070024257791026e-05, 0.000777702668357...</td>\n",
       "      <td>[[150.0, 149.99902556722168, 149.9892707777031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[0.0, 7.080212373649564e-05, 0.000778823361101...</td>\n",
       "      <td>[[150.0, 149.9990135426854, 149.98913848930934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>[0.0, 7.121243853914714e-05, 0.000783336823930...</td>\n",
       "      <td>[[150.0, 149.99896509835443, 149.9886055279389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.0, 7.173169075009221e-05, 0.000789048598251...</td>\n",
       "      <td>[[150.0, 149.9989037533709, 149.98793064155507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 7.070024262673938e-05, 0.000777702668894...</td>\n",
       "      <td>[[150.0, 149.99908289221426, 149.9899025648276...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.0, 7.173172356692081e-05, 0.000789048959236...</td>\n",
       "      <td>[[183.33333333333331, 183.33249451902495, 183....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 7.0700274931474e-05, 0.00077770302424621...</td>\n",
       "      <td>[[183.33333333333331, 183.33266080401245, 183....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[0.0, 7.080215613719611e-05, 0.000778823717509...</td>\n",
       "      <td>[[183.33333333333331, 183.33264685449788, 183....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>[0.0, 7.121247112970618e-05, 0.000783337182426...</td>\n",
       "      <td>[[183.33333333333331, 183.33259065378664, 183....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.0, 7.173172358096466e-05, 0.000789048959390...</td>\n",
       "      <td>[[183.33333333333331, 183.3325194845025, 183.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Resources  Uninfected Bacteria  e_vector  tau_vector  K_matrix  \\\n",
       "0          150.0                 35.0       0.1         0.7      10.0   \n",
       "1          150.0                 35.0       0.1         0.7      10.0   \n",
       "2          150.0                 35.0       0.1         0.7      10.0   \n",
       "3          150.0                 35.0       0.1         0.7      10.0   \n",
       "32         150.0                 35.0       0.1         0.7      20.0   \n",
       "...          ...                  ...       ...         ...       ...   \n",
       "2659  183.333333                 35.0       0.1         0.7      90.0   \n",
       "2688  183.333333                 35.0       0.1         0.7     100.0   \n",
       "2689  183.333333                 35.0       0.1         0.7     100.0   \n",
       "2690  183.333333                 35.0       0.1         0.7     100.0   \n",
       "2691  183.333333                 35.0       0.1         0.7     100.0   \n",
       "\n",
       "      B_matrix  washout                                           t_values  \\\n",
       "0         10.0      0.0  [0.0, 7.070024257791026e-05, 0.000777702668357...   \n",
       "1         10.0    0.001  [0.0, 7.080212373649564e-05, 0.000778823361101...   \n",
       "2         10.0    0.005  [0.0, 7.121243853914714e-05, 0.000783336823930...   \n",
       "3         10.0     0.01  [0.0, 7.173169075009221e-05, 0.000789048598251...   \n",
       "32        10.0      0.0  [0.0, 7.070024262673938e-05, 0.000777702668894...   \n",
       "...        ...      ...                                                ...   \n",
       "2659      10.0     0.01  [0.0, 7.173172356692081e-05, 0.000789048959236...   \n",
       "2688      10.0      0.0  [0.0, 7.0700274931474e-05, 0.00077770302424621...   \n",
       "2689      10.0    0.001  [0.0, 7.080215613719611e-05, 0.000778823717509...   \n",
       "2690      10.0    0.005  [0.0, 7.121247112970618e-05, 0.000783337182426...   \n",
       "2691      10.0     0.01  [0.0, 7.173172358096466e-05, 0.000789048959390...   \n",
       "\n",
       "                                               y_values  \n",
       "0     [[150.0, 149.99902556722168, 149.9892707777031...  \n",
       "1     [[150.0, 149.9990135426854, 149.98913848930934...  \n",
       "2     [[150.0, 149.99896509835443, 149.9886055279389...  \n",
       "3     [[150.0, 149.9989037533709, 149.98793064155507...  \n",
       "32    [[150.0, 149.99908289221426, 149.9899025648276...  \n",
       "...                                                 ...  \n",
       "2659  [[183.33333333333331, 183.33249451902495, 183....  \n",
       "2688  [[183.33333333333331, 183.33266080401245, 183....  \n",
       "2689  [[183.33333333333331, 183.33264685449788, 183....  \n",
       "2690  [[183.33333333333331, 183.33259065378664, 183....  \n",
       "2691  [[183.33333333333331, 183.3325194845025, 183.3...  \n",
       "\n",
       "[1240 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for sub table: 8.148431062698364 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the Parquet file\n",
    "# df = pd.read_csv('simulation_results.parquet')\n",
    "import sys\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "parquet_file_path = 'SimulationResults/UltimateAnalysis/simulation_results_1746524442.parquet'\n",
    "time1 = time.time()\n",
    "ddf = dd.read_parquet(parquet_file_path, engine='pyarrow', \n",
    "                      include_partition_columns=True, \n",
    "                      gather_statistics=True, \n",
    "                    #   columns=['Resources', 'Uninfected Bacteria', 'e_vector', 't_values'], \n",
    "                    #   filters=[('Resources', '==', \"2.0\"), (\"Uninfected Bacteria\", \">=\", \"11.1\")], \n",
    "                      dtype_backend='pyarrow')\n",
    "# ddf['Resources'] = ddf['Resources'].astype('float64')\n",
    "# ddf['e_vector'] = ddf['e_vector'].astype('float64')\n",
    "time2 = time.time()\n",
    "execution_time = time2 - time1\n",
    "print(f\"Execution time loading file: {execution_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "# display(ddf.compute().head())\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time computing whole tbale: {execution_time} seconds\")\n",
    "\n",
    "# Query the data in parquet_data\n",
    "# Filter rows where 'Resources' is equal to 150\n",
    "# filtered_data = ddf.query('tau_vector>= 0.7')\n",
    "# result = filtered_data.compute()\n",
    "# display(result)\n",
    "res = ddf.query(\"e_vector == 0.1 and tau_vector == 0.7 and B_matrix == 10\")\n",
    "# display(ddf.head())\n",
    "time1 = time.time()\n",
    "display(res.compute())\n",
    "time2 = time.time()\n",
    "execution_time = time2 - time1\n",
    "print(f\"Execution time for sub table: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac98a2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
