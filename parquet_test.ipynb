{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aede52b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'example_3.gexf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m flattened_y1\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# graph = GraphMakerGUI()\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# graph.export_graph('simple_test.gexf')\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# graph = System('simple_test.gexf')\u001b[39;00m\n\u001b[32m    101\u001b[39m \n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# graph = System('example.gexf')\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# system = System('simple_test_2.gexf')\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m system = \u001b[43mSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexample_3.gexf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# system.add_item_to_class_attribute('M', 4) # add the M value to the system\u001b[39;00m\n\u001b[32m    107\u001b[39m phage_nodes = system.get_nodes_of_type(\u001b[33m'\u001b[39m\u001b[33mP\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mSystem.__init__\u001b[39m\u001b[34m(self, graph_location)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph_location):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgraph_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/Classes/Analysis.py:21\u001b[39m, in \u001b[36mAnalysis.__init__\u001b[39m\u001b[34m(self, graph_location)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Given a graph file, this class will read in the graph file and store the graph as an attribute. It will also store the location of the graph file as an attribute. The class contains methods to extract the data from nodes and return it as a vector. It also contains methods to initialize matrices and vectors from the graph file and store the parameters of that data in the matrix to do vector-matrix calculations in the ODE system. The class also contains a method to solve the ODE system given the ODE system function, initial conditions, and parameters, and has a method to check for cutoff values to set to 0. Given an evironment node, it will store the parameters of the environment as attributes of the class, like temeprature, pH, time step, and simulation length, or any other given parameters.\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[33;03mThe user needs to provide their own implementation of the ODE system function, and the class will take care of the rest of the calculations and data extraction from the graph file. The user needs to ensure that the flattened vector is unflattened to the associated arrays and matrices to do the calculations, and then reflattened to return the derivative of the system. The user needs to provide the extra parameters to use when calling solve_system() for use in the method. The user needs to unpack the *args values correctly to use those parameters. The user can optionally check for cutoff values by calling check_cutoff() to set small values to 0. The user needs to repack the ODE data into a single vector to then be calculated. \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \u001b[33;03m    graph_location (str): location of the graph file to be read in\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mself\u001b[39m.graph_location = graph_location \u001b[38;5;66;03m# graph file location\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28mself\u001b[39m.graph = \u001b[43mnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_gexf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_location\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# read in the graph file\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.settings = {} \u001b[38;5;66;03m# settings for the class, can be used to set the parameters for the ODE system, like the time step, simulation length, and cutoff value\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.min_step = \u001b[32m0.01\u001b[39m \u001b[38;5;66;03m# default min step, backup in case the user does not set it\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/networkx/utils/decorators.py:788\u001b[39m, in \u001b[36margmap.__call__.<locals>.func\u001b[39m\u001b[34m(_argmap__wrapper, *args, **kwargs)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc\u001b[39m(*args, __wrapper=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<class 'networkx.utils.decorators.argmap'> compilation 6:3\u001b[39m, in \u001b[36margmap_read_gexf_1\u001b[39m\u001b[34m(path, node_type, relabel, version, backend, **backend_kwargs)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbz2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/networkx/utils/decorators.py:198\u001b[39m, in \u001b[36mopen_file.<locals>._open_file\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# could be None, or a file handle, in which case the algorithm will deal with it\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m path, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m fobj = \u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fobj, \u001b[38;5;28;01mlambda\u001b[39;00m: fobj.close()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'example_3.gexf'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import numpy as np\n",
    "from Classes.Analysis import Analysis\n",
    "from Classes.Visualizer import Visualizer\n",
    "import h5py\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from Classes.UltimateAnalysis import UltimateAnalysis\n",
    "import dask.dataframe as dd\n",
    "\n",
    "class System(Analysis):\n",
    "    def __init__(self, graph_location):\n",
    "        super().__init__(graph_location)\n",
    "\n",
    "    def odesystem(self, t, Y, *params):\n",
    "        # start simple, bacteria-resource, see how the bacteria and reosurces grow/shrink, bacteria should hit carrying capacity, resource should reach 0, not negative, etc\n",
    "        graph_object, phage_nodes, bacteria_nodes, resource_nodes, M, e_vector, tau_vector, v_matrix, K_matrix, r_matrix, B_matrix, environment = params\n",
    "        graph = graph_object.graph\n",
    "        def g(N, v, K):\n",
    "            return (N * v) / (N + K)\n",
    "\n",
    "        Y = self.check_cutoff(Y)\n",
    "        \n",
    "        N, U, I, P = self.unflatten_initial_matrix(Y, [len(resource_nodes), len(bacteria_nodes), (len(bacteria_nodes), M), len(phage_nodes)])\n",
    "        new_N = np.zeros_like(N)\n",
    "        new_U = np.zeros_like(U)\n",
    "        new_I = np.zeros_like(I)\n",
    "        new_P = np.zeros_like(P)\n",
    "        #update N vector\n",
    "        for resource in resource_nodes:\n",
    "            n_index = resource_nodes.index(resource)\n",
    "            e_value = e_vector[n_index] \n",
    "            sum_g = 0\n",
    "            sum_u = 0\n",
    "            sum_i = 0\n",
    "            for bacteria in bacteria_nodes:\n",
    "                b_index = bacteria_nodes.index(bacteria)\n",
    "                if graph.has_edge(bacteria, resource):\n",
    "                    v = v_matrix[b_index, n_index]\n",
    "                    K = K_matrix[b_index, n_index]\n",
    "                    sum_g += g(N[n_index], v, K)\n",
    "                    sum_u += U[b_index]\n",
    "                    sum_i += np.sum(I[b_index])\n",
    "            new_N[n_index] = -(e_value * sum_g) * (sum_u + sum_i) - N[n_index] * environment['washout']\n",
    "        \n",
    "        # update U vector, i, and j are flipped relative to what is seen in update N vector for v, K, and r matrices because of how the row and columns are defined in the graph\n",
    "        # dont sum U in left and right, because we are looking at an individual bacteria\n",
    "        for uninfected in bacteria_nodes:\n",
    "            u_index = bacteria_nodes.index(uninfected)\n",
    "            g_sum = 0\n",
    "            right = 0\n",
    "            for resource in resource_nodes:\n",
    "                n_index = resource_nodes.index(resource)\n",
    "                if graph.has_edge(uninfected, resource):\n",
    "                    g_sum += g(N[n_index], v_matrix[u_index, n_index], K_matrix[u_index, n_index])\n",
    "            for phage in phage_nodes:\n",
    "                p_index = phage_nodes.index(phage)\n",
    "                if graph.has_edge(phage, uninfected):\n",
    "                    right += r_matrix[p_index, u_index] * P[p_index]\n",
    "            new_U[u_index] = g_sum * U[u_index] - right * U[u_index] - U[u_index] * environment['washout']\n",
    "\n",
    "        for infected in bacteria_nodes:\n",
    "            i_index = bacteria_nodes.index(infected)\n",
    "            for infected_stage in range(0, M):\n",
    "                if infected_stage == 0:\n",
    "                    left_sum = 0\n",
    "                    right_sum = 0\n",
    "                    for phage in phage_nodes:\n",
    "                        p_index = phage_nodes.index(phage)\n",
    "                        if graph.has_edge(phage, infected):\n",
    "                            left_sum += r_matrix[p_index, i_index] * P[p_index]\n",
    "                            right_sum += M / tau_vector[i_index] * I[i_index, 0]\n",
    "                    new_I[i_index, 0] = left_sum * U[i_index] - right_sum - U[i_index] * environment['washout']\n",
    "                else:\n",
    "                    m_tau = M / tau_vector[i_index]\n",
    "                    right = I[i_index, infected_stage - 1] - I[i_index, infected_stage]\n",
    "                    new_I[i_index, infected_stage] = m_tau * right - new_I[i_index, infected_stage] * environment['washout']\n",
    "        \n",
    "        for phage in phage_nodes:\n",
    "            p_index = phage_nodes.index(phage)\n",
    "            left_sum = 0\n",
    "            right_sum = 0\n",
    "            for infected in bacteria_nodes:\n",
    "                i_index = bacteria_nodes.index(infected)\n",
    "                if graph.has_edge(phage, infected):\n",
    "                    left_sum += B_matrix[p_index, i_index] * M / tau_vector[i_index] * I[i_index, -1]\n",
    "                    right_sum += r_matrix[p_index, i_index] * (U[i_index] + np.sum(I[i_index])) * P[p_index]\n",
    "            new_P[p_index] = left_sum - right_sum - P[p_index] * environment['washout']\n",
    "\n",
    "        flattened_y1 = self.flatten_lists_and_matrices(new_N, new_U, new_I, new_P)\n",
    "        return flattened_y1\n",
    "\n",
    "\n",
    "# graph = GraphMakerGUI()\n",
    "# graph.export_graph('simple_test.gexf')\n",
    "# graph = System('simple_test.gexf')\n",
    "\n",
    "# graph = System('example.gexf')\n",
    "# system = System('simple_test_2.gexf')\n",
    "system = System('example_3.gexf')\n",
    "# system.add_item_to_class_attribute('M', 4) # add the M value to the system\n",
    "\n",
    "phage_nodes = system.get_nodes_of_type('P')\n",
    "bacteria_nodes = system.get_nodes_of_type('B')\n",
    "resource_nodes = system.get_nodes_of_type('R')\n",
    "environemnt_nodes = system.get_nodes_of_type('E')\n",
    "\n",
    "R0 = system.initialize_new_parameter_from_node(resource_nodes, \"Initial_Concentration\")\n",
    "U0 = system.initialize_new_parameter_from_node(bacteria_nodes, \"Initial_Population\")\n",
    "I0 = system.initialize_new_matrix(len(U0), system.M)\n",
    "P0 = system.initialize_new_parameter_from_node(phage_nodes, \"Initial_Population\")\n",
    "\n",
    "e_vector = system.initialize_new_parameter_from_node(resource_nodes, 'e')\n",
    "tau_vector = system.initialize_new_parameter_from_node(bacteria_nodes, 'tau')\n",
    "v_matrix = system.initialize_new_parameter_from_edges(bacteria_nodes, resource_nodes, 'v')\n",
    "K_matrix = system.initialize_new_parameter_from_edges(bacteria_nodes, resource_nodes, 'K')\n",
    "r_matrix = system.initialize_new_parameter_from_edges(phage_nodes, bacteria_nodes, 'r')\n",
    "B_matrix = system.initialize_new_parameter_from_edges(phage_nodes, bacteria_nodes, 'Burst_Size')\n",
    "\n",
    "visualizer = Visualizer(system)\n",
    "visualizer.add_graph_data(\"Resources\", R0, resource_nodes)\n",
    "visualizer.add_graph_data(\"Uninfected Bacteria\", U0, bacteria_nodes)\n",
    "visualizer.add_graph_data(\"Infected Bacteria\", I0, row_names=bacteria_nodes, column_names=[f\"Infected B{i}\" for i in range(int(system.M))], add_rows=4)\n",
    "visualizer.add_graph_data(\"Phages\", P0 , phage_nodes)\n",
    "\n",
    "visualizer.add_non_graph_data_vector(\"e_vector\", e_vector, resource_nodes)\n",
    "visualizer.add_non_graph_data_vector(\"tau_vector\", tau_vector, bacteria_nodes)\n",
    "visualizer.add_non_graph_data_matrix(\"v_matrix\", v_matrix, bacteria_nodes, resource_nodes)\n",
    "visualizer.add_non_graph_data_matrix(\"K_matrix\", K_matrix, bacteria_nodes, resource_nodes)\n",
    "visualizer.add_non_graph_data_matrix(\"r_matrix\", r_matrix, phage_nodes, bacteria_nodes)\n",
    "visualizer.add_non_graph_data_matrix(\"B_matrix\", B_matrix, phage_nodes, bacteria_nodes)\n",
    "\n",
    "visualizer.add_other_parameters(phage_nodes, bacteria_nodes, resource_nodes, int(system.M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.integrate import solve_ivp\n",
    "\n",
    "# t_eval = np.linspace(0, 20, 100)\n",
    "# paramater_names = ['a', 'b', 'c']\n",
    "# params_to_test = [[1, 2, 3], [4, 5, 6], [1, 8, 9], [7, 8, 9], [1, 5, 3]]\n",
    "\n",
    "# def function(t, a):\n",
    "#     a_val, b_val, c_val = a[0], a[1], a[2]\n",
    "#     # Simulate function returning a NumPy array (like time or y data)\n",
    "#     return np.array([0.1 * a_val + b_val, 2.3 * c_val, a_val * c_val])\n",
    "# values = Parallel(n_jobs=-1)(delayed(\n",
    "#     lambda x: solve_ivp(function, (0, 20), x)\n",
    "# )(x) for x in params_to_test)\n",
    "\n",
    "# output_filename = 'function_results_test.hdf5'\n",
    "# with h5py.File(output_filename, 'w') as hf:\n",
    "#     # Add metadata to the root of the file\n",
    "#     hf.attrs['parameter_names_used'] = paramater_names  # Store metadata as attributes\n",
    "#     hf.attrs['parameter_values_tested'] = params_to_test  # Store analysis object as an attribute\n",
    "\n",
    "#     # Create a group to store the results\n",
    "#     # Store the parameters as a dataset\n",
    "#     # results_group.create_dataset('parameter_values_tested', data=np.array(params_to_test))\n",
    "#     for i, item in enumerate(values):\n",
    "#         results_group = hf.create_group(f'results_{i+1}')\n",
    "#         results_group.create_dataset(f'y_values', data=item.y)\n",
    "#         results_group.create_dataset(f't_values', data=item.t)\n",
    "#         for param_name, param_value in zip(paramater_names, params_to_test[i]):\n",
    "#             results_group.attrs[param_name] = param_value  # Store parameter values as attributes\n",
    "# hf.close()\n",
    "\n",
    "# print(f\"Results and parameters saved to {output_filename}\")\n",
    "\n",
    "# dictionary = {\n",
    "#     'parameter_names_used': paramater_names,\n",
    "#     'parameter_values_tested': params_to_test,\n",
    "#     'analysis': visualizer.analysis,\n",
    "#     'graph_data': visualizer.graph_data,\n",
    "#     'non_graph_data_vector': visualizer.non_graph_data_vector,\n",
    "#     'non_graph_data_matrix': visualizer.non_graph_data_matrix,\n",
    "#     'settings': visualizer.settings,\n",
    "#     'environment_data': visualizer.analysis.environment_data,\n",
    "#     'other_parameters': visualizer.other_parameters_to_pass,\n",
    "#     'hdf_file_location': 'function_results_test.hdf5',\n",
    "# }\n",
    "\n",
    "# pickle.dump(dictionary, open('function_results_test.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77801778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ua = UltimateAnalysis()\n",
    "# ua.unpack_pickle('function_results_test.pickle')\n",
    "# query1 = ua.new_query()\n",
    "\n",
    "# with h5py.File(query1, 'r') as query_in_memory:\n",
    "#     print(\"original dataset\", list(query_in_memory.keys()))\n",
    "\n",
    "\n",
    "# d = ua.simple_query(query1, 'Infected Bacteria', '==', 7)\n",
    "# with h5py.File(d, 'r') as d_in_memory:\n",
    "#     print(\"simulations with infected==7\", list(d_in_memory.keys()))\n",
    "\n",
    "# e = ua.simple_query(query1, 'Infected Bacteria', '==', 8)\n",
    "# with h5py.File(e, 'r') as e_in_memory:\n",
    "#     print(\"simulations with infected==8\", list(e_in_memory.keys())) \n",
    "\n",
    "# f = ua.simple_query(e, 'Resources', '>=', 2)\n",
    "# with h5py.File(f, 'r') as f_in_memory:\n",
    "#     print(\"simulations with Resources >=2\", list(f_in_memory.keys())) \n",
    "\n",
    "# g = ua.and_query(query1, ['Infected Bacteria', 'Resources'], ['==', '=='], [9, 1])\n",
    "# with h5py.File(g, 'r') as g_in_memory:\n",
    "#     print(\"simulations with infected=9 and Resources==1\", list(g_in_memory.keys())) \n",
    "\n",
    "# h = ua.or_query(query1, ['Resources', 'Resources'], ['<', '>'], [2, 2])\n",
    "# with h5py.File(h, 'r') as h_in_memory:\n",
    "#     print(\"simulations with resources<2 or Resources>2\", list(h_in_memory.keys())) \n",
    "\n",
    "# dictionary = ua.finalize_query(h)\n",
    "# print(dictionary)\n",
    "# dataframe = ua.finalize_query(d, format='dataframe')\n",
    "# save dataframe to csv\n",
    "# dataframe[dataframe['Resources'] == 1]\n",
    "# print(dataframe.iloc[0]['t_values'])\n",
    "# for i in range(0, len(dataframe.iloc[0]['y_values'])):\n",
    "#     print(dataframe.iloc[0]['y_values'][i])\n",
    "# print(d)\n",
    "# d2 = ua.simple_query(d, 'Resources', '==', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e65acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from pprint import pprint\n",
    "\n",
    "# pickle_object = pd.read_pickle('simulation_results.pickle')\n",
    "# dataframe = pickle_object['simulation_results']\n",
    "# dfr10 = dataframe[dataframe['Resources'] == 1]\n",
    "# print(dfr10)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Values\")\n",
    "# sim1 = dataframe.iloc[0]\n",
    "# for i in range(len(sim1['y_values'])):\n",
    "#     plt.plot(sim1['t_values'], sim1['y_values'][i], label=f\"item {i}\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "508b2912",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SimulationResults/UltimateAnalysis/simulation_results_1747785253.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m parquet_file_path = \u001b[33m'\u001b[39m\u001b[33mSimulationResults/UltimateAnalysis/simulation_results_1747782459.parquet\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     22\u001b[39m pickle_file_path = \u001b[33m'\u001b[39m\u001b[33mSimulationResults/UltimateAnalysis/simulation_results_1747785253.pickle\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpickle_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     24\u001b[39m     pickle_data = pickle.load(f)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKeys in pickle file:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'SimulationResults/UltimateAnalysis/simulation_results_1747785253.pickle'"
     ]
    }
   ],
   "source": [
    "# Load the Parquet file\n",
    "# df = pd.read_csv('simulation_results.parquet')\n",
    "import sys\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "from IPython.display import display\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "parquet_file_path = 'SimulationResults/UltimateAnalysis/simulation_results_1747782459.parquet'\n",
    "pickle_file_path = 'SimulationResults/UltimateAnalysis/simulation_results_1747785253.pickle'\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "print(\"Keys in pickle file:\")\n",
    "pprint(list(pickle_data.keys()))\n",
    "\n",
    "\n",
    "ddf = dd.read_parquet(parquet_file_path, engine='pyarrow', \n",
    "                      include_partition_columns=True, \n",
    "                      gather_statistics=True, \n",
    "                    #   columns=['Resources', 'Uninfected Bacteria', 'e_vector', 't_values'], \n",
    "                      filters=[('Resources', '==', \"2.0\"), (\"Uninfected Bacteria\", \">=\", \"11.1\")], \n",
    "                      dtype_backend='pyarrow')\n",
    "ddf['Resources'] = ddf['Resources'].astype('float64')\n",
    "# ddf['e_vector'] = ddf['tau_vector'].astype('float64')\n",
    "# ddf['Resources'] = ddf['Resources'].replace(\"inf\", np.inf)\n",
    "ddf = ddf.query('Resources == 1')\n",
    "display(ddf.compute().head())\n",
    "print(ddf['t_values'].dtype)\n",
    "\n",
    "# Convert the 't_values' and 'y_values' columns from string to numpy arrays\n",
    "ddf['t_values'] = ddf['t_values'].map(lambda x: np.fromstring(x.strip('[]'), sep=','), meta=('t_values', 'object'))\n",
    "ddf['y_values'] = ddf['y_values'].map(lambda x: np.array([float(i) for i in x.strip('[]').split(',')]), meta=('y_values', 'object'))\n",
    "# print(ddf.compute().head())\n",
    "# Query the data in parquet_data\n",
    "# Filter rows where 'Resources' is equal to 150\n",
    "# filtered_data = ddf.query('tau_vector>= 0.7')\n",
    "# result = filtered_data.compute()\n",
    "# display(result)\n",
    "# res = ddf.query(\"Resources >= 160\")\n",
    "\n",
    "# ddf = ddf.rename(columns={'Uninfected Bacteria': 'Uninfected_Bacteria'})\n",
    "# filtered_data = ddf.query('Resources == inf')\n",
    "# filtered_data = filtered_data.query(\"tau_vector == inf\")\n",
    "# print(filtered_data.compute().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f173e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vicpi/Documents/GitHub/Master_Thesis/.venv/lib/python3.11/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 63220 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "import dask\n",
    "client = Client(threads_per_worker=4, n_workers=1)\n",
    "# client\n",
    "def import_and_filter_parquet():\n",
    "    parquet_file_path = 'SimulationResults/UltimateAnalysis/simulation_results_1747765287.parquet'\n",
    "    parquet_data = dd.read_parquet(parquet_file_path)\n",
    "    # Query the data in parquet_data\n",
    "    # Filter rows where 'Resources' is equal to 150\n",
    "    filtered_data = parquet_data.query('Resources == 1')\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [v_matrix, K_matrix, t_values, y_values, Resources, tau_vector]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "lazy_result = dask.delayed(import_and_filter_parquet)()\n",
    "filtered_data = dask.compute(lazy_result)\n",
    "# result = filtered_data.compute()\n",
    "print(filtered_data[0].compute().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time loading file: 0.03380131721496582 seconds\n",
      "Execution time computing whole tbale: 1.811981201171875e-05 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resources</th>\n",
       "      <th>Uninfected Bacteria</th>\n",
       "      <th>e_vector</th>\n",
       "      <th>tau_vector</th>\n",
       "      <th>K_matrix</th>\n",
       "      <th>B_matrix</th>\n",
       "      <th>washout</th>\n",
       "      <th>t_values</th>\n",
       "      <th>y_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 7.070024257791026e-05, 0.000777702668357...</td>\n",
       "      <td>[[150.0, 149.99902556722168, 149.9892707777031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[0.0, 7.080212373649564e-05, 0.000778823361101...</td>\n",
       "      <td>[[150.0, 149.9990135426854, 149.98913848930934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>[0.0, 7.121243853914714e-05, 0.000783336823930...</td>\n",
       "      <td>[[150.0, 149.99896509835443, 149.9886055279389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.0, 7.173169075009221e-05, 0.000789048598251...</td>\n",
       "      <td>[[150.0, 149.9989037533709, 149.98793064155507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>150.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 7.070024262673938e-05, 0.000777702668894...</td>\n",
       "      <td>[[150.0, 149.99908289221426, 149.9899025648276...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.0, 7.173172356692081e-05, 0.000789048959236...</td>\n",
       "      <td>[[183.33333333333331, 183.33249451902495, 183....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 7.0700274931474e-05, 0.00077770302424621...</td>\n",
       "      <td>[[183.33333333333331, 183.33266080401245, 183....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[0.0, 7.080215613719611e-05, 0.000778823717509...</td>\n",
       "      <td>[[183.33333333333331, 183.33264685449788, 183....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>[0.0, 7.121247112970618e-05, 0.000783337182426...</td>\n",
       "      <td>[[183.33333333333331, 183.33259065378664, 183....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.0, 7.173172358096466e-05, 0.000789048959390...</td>\n",
       "      <td>[[183.33333333333331, 183.3325194845025, 183.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Resources  Uninfected Bacteria  e_vector  tau_vector  K_matrix  \\\n",
       "0          150.0                 35.0       0.1         0.7      10.0   \n",
       "1          150.0                 35.0       0.1         0.7      10.0   \n",
       "2          150.0                 35.0       0.1         0.7      10.0   \n",
       "3          150.0                 35.0       0.1         0.7      10.0   \n",
       "32         150.0                 35.0       0.1         0.7      20.0   \n",
       "...          ...                  ...       ...         ...       ...   \n",
       "2659  183.333333                 35.0       0.1         0.7      90.0   \n",
       "2688  183.333333                 35.0       0.1         0.7     100.0   \n",
       "2689  183.333333                 35.0       0.1         0.7     100.0   \n",
       "2690  183.333333                 35.0       0.1         0.7     100.0   \n",
       "2691  183.333333                 35.0       0.1         0.7     100.0   \n",
       "\n",
       "      B_matrix  washout                                           t_values  \\\n",
       "0         10.0      0.0  [0.0, 7.070024257791026e-05, 0.000777702668357...   \n",
       "1         10.0    0.001  [0.0, 7.080212373649564e-05, 0.000778823361101...   \n",
       "2         10.0    0.005  [0.0, 7.121243853914714e-05, 0.000783336823930...   \n",
       "3         10.0     0.01  [0.0, 7.173169075009221e-05, 0.000789048598251...   \n",
       "32        10.0      0.0  [0.0, 7.070024262673938e-05, 0.000777702668894...   \n",
       "...        ...      ...                                                ...   \n",
       "2659      10.0     0.01  [0.0, 7.173172356692081e-05, 0.000789048959236...   \n",
       "2688      10.0      0.0  [0.0, 7.0700274931474e-05, 0.00077770302424621...   \n",
       "2689      10.0    0.001  [0.0, 7.080215613719611e-05, 0.000778823717509...   \n",
       "2690      10.0    0.005  [0.0, 7.121247112970618e-05, 0.000783337182426...   \n",
       "2691      10.0     0.01  [0.0, 7.173172358096466e-05, 0.000789048959390...   \n",
       "\n",
       "                                               y_values  \n",
       "0     [[150.0, 149.99902556722168, 149.9892707777031...  \n",
       "1     [[150.0, 149.9990135426854, 149.98913848930934...  \n",
       "2     [[150.0, 149.99896509835443, 149.9886055279389...  \n",
       "3     [[150.0, 149.9989037533709, 149.98793064155507...  \n",
       "32    [[150.0, 149.99908289221426, 149.9899025648276...  \n",
       "...                                                 ...  \n",
       "2659  [[183.33333333333331, 183.33249451902495, 183....  \n",
       "2688  [[183.33333333333331, 183.33266080401245, 183....  \n",
       "2689  [[183.33333333333331, 183.33264685449788, 183....  \n",
       "2690  [[183.33333333333331, 183.33259065378664, 183....  \n",
       "2691  [[183.33333333333331, 183.3325194845025, 183.3...  \n",
       "\n",
       "[1240 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for sub table: 8.148431062698364 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the Parquet file\n",
    "# df = pd.read_csv('simulation_results.parquet')\n",
    "import sys\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "parquet_file_path = 'SimulationResults/UltimateAnalysis/simulation_results_1746524442.parquet'\n",
    "time1 = time.time()\n",
    "ddf = dd.read_parquet(parquet_file_path, engine='pyarrow', \n",
    "                      include_partition_columns=True, \n",
    "                      gather_statistics=True, \n",
    "                    #   columns=['Resources', 'Uninfected Bacteria', 'e_vector', 't_values'], \n",
    "                    #   filters=[('Resources', '==', \"2.0\"), (\"Uninfected Bacteria\", \">=\", \"11.1\")], \n",
    "                      dtype_backend='pyarrow')\n",
    "# ddf['Resources'] = ddf['Resources'].astype('float64')\n",
    "# ddf['e_vector'] = ddf['e_vector'].astype('float64')\n",
    "time2 = time.time()\n",
    "execution_time = time2 - time1\n",
    "print(f\"Execution time loading file: {execution_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "# display(ddf.compute().head())\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time computing whole tbale: {execution_time} seconds\")\n",
    "\n",
    "# Query the data in parquet_data\n",
    "# Filter rows where 'Resources' is equal to 150\n",
    "# filtered_data = ddf.query('tau_vector>= 0.7')\n",
    "# result = filtered_data.compute()\n",
    "# display(result)\n",
    "res = ddf.query(\"e_vector == 0.1 and tau_vector == 0.7 and B_matrix == 10\")\n",
    "# display(ddf.head())\n",
    "time1 = time.time()\n",
    "display(res.compute())\n",
    "time2 = time.time()\n",
    "execution_time = time2 - time1\n",
    "print(f\"Execution time for sub table: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac98a2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5544, 0.4456],\n",
       "       [0.8811, 0.1189]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "s = '[[ 0.5544,  0.4456], [ 0.8811,  0.1189]]'\n",
    "np.array(ast.literal_eval(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324b5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
